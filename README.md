|Milestone|Colab badge|
| ----------- | ----------- |
| Milestone 1      | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Henya14/deep-learning-ner/blob/main/data_visualization.ipynb) |
| Milestone 2        | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Henya14/deep-learning-ner/blob/main/basic_training.ipynb) |


# Group info â„¹

## Name: NER ğŸ’¸
## Group members ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦
| Name      | Neptun |
| ----------- | ----------- |
| Ã‰lÅ‘ Henrik Rudolf      | HR2JO3 |
| ZahorÃ¡n Marcell        | E5ZY9R |
| CsÃ¡szÃ¡r KristÃ³f        | DPCIMG |

# About the project ğŸ“š
In this project we make an NLP based hungarian NER model using deep neural networks.

# Project files ğŸ“ƒ
The data directory holds all the data for training and validation. The model will use the .csv files, but we kept the original .conllup files just in case. 

- `data_visualization.ipynb` contains the downloading and preparation of the training data.
- `basic_training.ipynb` contains the basic training and evaluation code

# Running the project ğŸƒâ€â™‚ï¸
You can simply run the project connected to each milestone by clicking on the corresponding badge on the top of this README file or if it suits you better you can open the .ipybn files here on github and click the badge there. 

Of course you are also welcome to clone the repo and run the ipynb files locally with jupyter notebook.

# Data ğŸ“Š
The data is from the [NYTK-NerKor](https://github.com/nytud/NYTK-NerKor) github repo. 

The files are annotated using the [CoNLL-U Plus](https://universaldependencies.org/ext-format.html) format.

Some info from the data's repo:

> The fiction subcorpus contains i) novels from MEK (Hungarian Electronic Library) and Project Gutenberg; and ii) subtitles from OpenSubtitles.

> The legal texts come from EU sources: it is a selection from the EU Constitution, documents from the European Economic and Social Committee, DGT-Acquis and JRC-Acquis.

> The sources of the news subcorpus are: Press Release Database of European Commission, Global Voices and NewsCrawl Corpus.

> Web texts contain a selection from the Hungarian [Webcorpus 2.0](https://hlt.bme.hu/en/resources/webcorpus2).

> Wikipedia texts are from the Hungarian Wikipedia. :)
